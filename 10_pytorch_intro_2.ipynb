{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5jLdN3JfU1SWAUmVcwNjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HammadN98/pytorch/blob/main/10_pytorch_intro_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducao ao Pytorch 2"
      ],
      "metadata": {
        "id": "oTHNKMWJtVPx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPJN3Z6StQJe",
        "outputId": "8e280b4e-8ce1-45f9-aa60-d2d798f07a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch 1.X"
      ],
      "metadata": {
        "id": "U6OXAsjmzsjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.vgg16()"
      ],
      "metadata": {
        "id": "BKDw175stzjF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Com a chegada do Pytorch 2.X"
      ],
      "metadata": {
        "id": "djwyXfCAz9li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "model_vgg = torchvision.models.vgg16() #QUase todos os modelos\n",
        "\n",
        "compiled_model = torch.compile(model_vgg)\n",
        "\n",
        "### Treino\n",
        "\n",
        "\n",
        "###Teste"
      ],
      "metadata": {
        "id": "L4ngk9bSz8qV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Configurando o ambiente"
      ],
      "metadata": {
        "id": "bQQF34LA0_s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Versao recente ja"
      ],
      "metadata": {
        "id": "elZKiKmz0nlI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Informacoes da GPU\n",
        "\n",
        "PQ pegar info da GPU?\n",
        "Pq o Pytorch 2 funciona melhor nas novas GPUs NVIDIA, foi criado para isso\n",
        "\n",
        "* Ter uma GPU com score de +8.0 o bagulho fica doido"
      ],
      "metadata": {
        "id": "HXXnoQYt1VkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upn-aOqV1VLl",
        "outputId": "b9a72fa7-a62a-4369-b792-596f6382ff39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 11 15:08:24 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Configurando o dispositivo de maneira global\n",
        "\n",
        "Antigamente tinha que configurar o dispositivo dos tensor/modelos:\n",
        "\n",
        "* `tensor.to(device)`\n",
        "* `model.to(device)`\n",
        "\n",
        "Porem com o pytorch 2.X e possivel configurar com \"Context manager\" e tambem de maneira global.\n"
      ],
      "metadata": {
        "id": "pg58wt-D6PZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#Configurando com \"context manager\"\n",
        "with torch.device(device):\n",
        "  layer = torch.nn.Linear(20, 30)\n",
        "  print(f\"Pessos da camada estao no dispositivo: {layer.weight.device}\")\n",
        "  print(f\"Camada criada no dispositivo: {layer(torch.randn(128, 20)).device}\")\n"
      ],
      "metadata": {
        "id": "Ryvv9YQ22_Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbf8e1a-d596-44b8-a2df-04888423e368"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pessos da camada estao no dispositivo: cuda:0\n",
            "Camada criada no dispositivo: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "#COnfigurando o disopositivo de maneira global\n",
        "torch.set_default_device(device)\n",
        "\n",
        "#Todos os tensors e objetos Pytorch criados apartir daqui estaram no dispositivo configurado sem a necessidade de usar o .to()\n",
        "layer = torch.nn.Linear(20, 30)\n",
        "print(f\"Pessos da camada estao no dispositivo: {layer.weight.device}\")\n",
        "print(f\"Camada criada no dispositivo: {layer(torch.randn(128, 20)).device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9RRXyQK7cRV",
        "outputId": "7c831f74-b5f7-45f7-9003-a5c25e17d828"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pessos da camada estao no dispositivo: cuda:0\n",
            "Camada criada no dispositivo: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Configurnado experimentos\n",
        "\n",
        "Para testar a \"nova\" velocidade do pytorch, serao realizados 4 experimentos, sendo eles com:\n",
        " * Modelo: ResNet50\n",
        " * Dados: CIFAR10 do torchvision\n",
        " * Epochs: 5 e 3x5(Com calculo da media)\n",
        " * Batch size 128\n",
        " * Iamge size 224"
      ],
      "metadata": {
        "id": "TlZJqz5cSDK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(f\"Versao do Pytorch: {torch.__version__}\")\n",
        "print(f\"Versao do Torchvision: {torchvision.__version__}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando: {device}\")\n"
      ],
      "metadata": {
        "id": "9kFpxs6C8Fji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d64354-838c-41f0-a608-711dc0d5d81b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versao do Pytorch: 2.5.1+cu121\n",
            "Versao do Torchvision: 0.20.1+cu121\n",
            "Usando: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Criando o modelo e os transforms\n",
        "\n",
        "* ResNet50"
      ],
      "metadata": {
        "id": "aBo4R1lW2OoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
        "transforms = model_weights.transforms()\n",
        "\n",
        "transforms"
      ],
      "metadata": {
        "id": "8BrCG4y3Tckp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d4074f-14b4-48bc-8432-41d9ec150be4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet50(weights=model_weights)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58fBN5Mx2mgT",
        "outputId": "50849560-91c3-429e-8823-85c0a44f402d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 196MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Contando a quantidade de parametros\n",
        "total_params = sum(\n",
        "    param.numel() for param in model.parameters() #COntando todos os paraemtros\n",
        "    #param.numel() for param in model.parameters() if param.requires_grad = True ||Contando apenas os parametros treinaveis.\n",
        ")\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-H_goDw2x8Z",
        "outputId": "8b076988-4029-44c0-dbc6-48b9a0f647b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25557032"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTA**  Os speedsup do 2.x serao mais notaveius quando for possivel usar a maior quantidade de processaento do GPU. Oq siginifica que modelo maiores(com mais paramentros treinaveis) levaram um tempo maior para serem treinados mas serao relativamente mais rapidos que modelos menores. EX: 1m de parametros leva 10 min, 25M de parametrso leva 25 min"
      ],
      "metadata": {
        "id": "RmfAzxob3W91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_classes=10):\n",
        "  \"\"\"\n",
        "  Cria um modelo ResNet50 com seus transformadores e devolve os dois\n",
        "  \"\"\"\n",
        "  model_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
        "  transforms = model_weights.transforms()\n",
        "  model = torchvision.models.resnet50(weights=model_weights)\n",
        "\n",
        "  #Ajustando a camada head para o nosso problema\n",
        "  model.fc = torch.nn.Linear(in_features=2048,\n",
        "                             out_features=num_classes)\n",
        "\n",
        "  return model, transforms\n",
        "\n",
        "model, transforms = create_model()\n",
        "transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9EP5Z0z3TEX",
        "outputId": "1d927bad-9ee0-4bf4-8755-a84c08a311dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 \"Speedups\" sao mais notaveis quando um grande porcao da GPU esta sendo usada\n",
        "\n",
        "Considerando que as GPUs modernas sao *Rapidas* performando operacoes, e possivel notar o aumentos de velocidade relativo quando se usa o maximo de dados possiveis na GPU.\n",
        "\n",
        "Na pratica, se quer usar o maximop da memoria da GPU\n",
        "\n",
        "* Aumentando o valor do batch size (USamos de 32, porem vale se possivel aumentar 128, 256, 512\n",
        "* Aumentando o tamanhodoas imagens\n",
        "* Aumentando o tamanho do modelo\n",
        "* Diminuindo a transferencia de dados ( CPU x GPU)\n",
        "\n",
        "Assim o tempo relativo deve melhorar, claro que o tempo tatal tambem ira aumentar\n"
      ],
      "metadata": {
        "id": "ZhPLl38B_T7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Chacado os limites de memoria da GPU disponivel\n",
        "\n",
        "Usando ```torch.cuda ```\n",
        "\n"
      ],
      "metadata": {
        "id": "ScjXoInk76Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\n",
        "print(f\"Memoria livre: {round(total_free_gpu_memory * 1e-9, 3)}GB\")\n",
        "print(f\"Memoria total da GPU: {round(total_gpu_memory * 1e-9, 3)}GB\")\n"
      ],
      "metadata": {
        "id": "mQSqmISs4vkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037b556a-18bf-4d57-8c52-8bb046db0eb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memoria livre: 15.453GB\n",
            "Memoria total da GPU: 15.836GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se a memoria for > 16gb usar batch de 128, caso contrario batch de 32"
      ],
      "metadata": {
        "id": "raW2H4-O8qFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_free_gpu_memory_gb = round(total_gpu_memory * 1e-9, 3)\n",
        "if total_free_gpu_memory_gb >= 16:\n",
        "  BATCH_SIZE = 128\n",
        "  IMAGE_SIZE = 224\n",
        "  print(f\"memoria disponivel: {total_free_gpu_memory_gb} GB, usando batch_size de {BATCH_SIZE} e image_size de {IMAGE_SIZE}\")\n",
        "else:\n",
        "  BATCH_SIZE = 32\n",
        "  IMAGE_SIZE = 128\n",
        "  print(f\"memoria disponivel: {total_free_gpu_memory_gb} GB, usando batch_size de {BATCH_SIZE} e image_size de {IMAGE_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWBJYd_U8Rqr",
        "outputId": "660b4bb5-7866-44d8-bbc4-b15cc0a118db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "memoria disponivel: 15.836 GB, usando batch_size de 32 e image_size de 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDDNlrSR9-lo",
        "outputId": "30cf00ec-2025-4c52-d2eb-0752a0335ec3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[232]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BILINEAR\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.crop_size = 224\n",
        "transforms.resize_size = 128\n",
        "print(f\"Transforms atualizados: \\n{transforms}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-0t6Qlj9Ydf",
        "outputId": "1eb9cdbf-9336-4466-f862-2c0ad9fc90b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforms atualizados: \n",
            "ImageClassification(\n",
            "    crop_size=224\n",
            "    resize_size=128\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BILINEAR\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Mais speedups com TF32\n",
        "\n",
        "TensorFloat32 -> um tipo de dado que combina Float32 e Float16:\n",
        "* Range com a quantidade de bits do FP32\n",
        "* Precisao com com a quantidade de bits do FP16"
      ],
      "metadata": {
        "id": "uYcPecK3JxaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.backends.cuda.matmul.allow_tf32 = True"
      ],
      "metadata": {
        "id": "SXRQ7_aF-MfV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dcX9v85kNBN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.CIFAR10(root=\".\",\n",
        "                                             train=True,\n",
        "                                             download=True,\n",
        "                                             transform=transforms)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\".\",\n",
        "                                           train=False,\n",
        "                                           download=True,\n",
        "                                           transform=transforms)\n",
        "\n",
        "train_len = len(train_dataset)\n",
        "test_len = len(test_dataset)\n",
        "\n",
        "print(f\"[INFO] Train dataset length: {train_len}\")\n",
        "print(f\"[INFO] Test dataset length: {test_len}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUDNusvlJtEZ",
        "outputId": "5fc9e229-b900-4b5b-9e27-4cdaca573f88"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n",
            "[INFO] Train dataset length: 50000\n",
            "[INFO] Test dataset length: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoaders"
      ],
      "metadata": {
        "id": "moBAqKVVSXVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True,\n",
        "                              num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_dataset,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False,\n",
        "                             num_workers=NUM_WORKERS)\n",
        "\n",
        "print(f\"{len(train_dataloader)} batches no dataloader de treino, de tamanho {BATCH_SIZE}\")\n",
        "print(f\"{len(test_dataloader)} batches no dataloader de teste, de tamanho {BATCH_SIZE}\")\n",
        "print(f\"Usando {NUM_WORKERS}  workers para carregar os dados da cpu para a gpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQk_bLjcSZgg",
        "outputId": "728ea272-e01c-4b77-b2be-72eae1a22f87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563 batches no dataloader de treino, de tamanho 32\n",
            "313 batches no dataloader de teste, de tamanho 32\n",
            "Usando 2  workers para carregar os dados da cpu para a gpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.7 Criando os loops de treino e teste\n",
        "\n",
        "No caso adicionando um temporizador para poder avaliar os experimentos.\n",
        "\n",
        "Usando o codigo ja feito em aulas passadas, apenas add o tempo"
      ],
      "metadata": {
        "id": "Gfsy1xZRUZLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def train_step(epoch: int,\n",
        "               model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device,\n",
        "               disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
        "  \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to training mode and then\n",
        "  runs through all of the required training steps (forward\n",
        "  pass, loss calculation, optimizer step).\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "\n",
        "    (0.1112, 0.8743)\n",
        "  \"\"\"\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through data loader data batches\n",
        "  progress_bar = tqdm(\n",
        "        enumerate(dataloader),\n",
        "        desc=f\"Training Epoch {epoch}\",\n",
        "        total=len(dataloader),\n",
        "        disable=disable_progress_bar\n",
        "    )\n",
        "\n",
        "  for batch, (X, y) in progress_bar:\n",
        "      # Send data to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Calculate  and accumulate loss\n",
        "      loss = loss_fn(y_pred, y)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # 3. Optimizer zero grad\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # 4. Loss backward\n",
        "      loss.backward()\n",
        "\n",
        "      # 5. Optimizer step\n",
        "      optimizer.step()\n",
        "\n",
        "      # Calculate and accumulate accuracy metrics across all batches\n",
        "      y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "      train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "      # Update progress bar\n",
        "      progress_bar.set_postfix(\n",
        "            {\n",
        "                \"train_loss\": train_loss / (batch + 1),\n",
        "                \"train_acc\": train_acc / (batch + 1),\n",
        "            }\n",
        "        )\n",
        "\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(epoch: int,\n",
        "              model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device,\n",
        "              disable_progress_bar: bool = False) -> Tuple[float, float]:\n",
        "  \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "  Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "  a forward pass on a testing dataset.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy). For example:\n",
        "\n",
        "    (0.0223, 0.8985)\n",
        "  \"\"\"\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Loop through data loader data batches\n",
        "  progress_bar = tqdm(\n",
        "      enumerate(dataloader),\n",
        "      desc=f\"Testing Epoch {epoch}\",\n",
        "      total=len(dataloader),\n",
        "      disable=disable_progress_bar\n",
        "  )\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.no_grad(): # no_grad() required for PyTorch 2.0, I found some errors with `torch.inference_mode()`, please let me know if this is not the case\n",
        "      # Loop through DataLoader batches\n",
        "      for batch, (X, y) in progress_bar:\n",
        "          # Send data to target device\n",
        "          X, y = X.to(device), y.to(device)\n",
        "\n",
        "          # 1. Forward pass\n",
        "          test_pred_logits = model(X)\n",
        "\n",
        "          # 2. Calculate and accumulate loss\n",
        "          loss = loss_fn(test_pred_logits, y)\n",
        "          test_loss += loss.item()\n",
        "\n",
        "          # Calculate and accumulate accuracy\n",
        "          test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "          test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "          # Update progress bar\n",
        "          progress_bar.set_postfix(\n",
        "              {\n",
        "                  \"test_loss\": test_loss / (batch + 1),\n",
        "                  \"test_acc\": test_acc / (batch + 1),\n",
        "              }\n",
        "          )\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  test_loss = test_loss / len(dataloader)\n",
        "  test_acc = test_acc / len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device,\n",
        "          disable_progress_bar: bool = False) -> Dict[str, List]:\n",
        "  \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "  Passes a target PyTorch models through train_step() and test_step()\n",
        "  functions for a number of epochs, training and testing the model\n",
        "  in the same epoch loop.\n",
        "\n",
        "  Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "  Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "  Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "                  train_acc: [...],\n",
        "                  test_loss: [...],\n",
        "                  test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "                 {train_loss: [2.0616, 1.0537],\n",
        "                  train_acc: [0.3945, 0.3945],\n",
        "                  test_loss: [1.2641, 1.5706],\n",
        "                  test_acc: [0.3400, 0.2973]}\n",
        "  \"\"\"\n",
        "  # Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": [],\n",
        "      \"train_epoch_time\": [],\n",
        "      \"test_epoch_time\": []\n",
        "  }\n",
        "\n",
        "  # Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs), disable=disable_progress_bar):\n",
        "\n",
        "      # Perform training step and time it\n",
        "      train_epoch_start_time = time.time()\n",
        "      train_loss, train_acc = train_step(epoch=epoch,\n",
        "                                        model=model,\n",
        "                                        dataloader=train_dataloader,\n",
        "                                        loss_fn=loss_fn,\n",
        "                                        optimizer=optimizer,\n",
        "                                        device=device,\n",
        "                                        disable_progress_bar=disable_progress_bar)\n",
        "      train_epoch_end_time = time.time()\n",
        "      train_epoch_time = train_epoch_end_time - train_epoch_start_time\n",
        "\n",
        "      # Perform testing step and time it\n",
        "      test_epoch_start_time = time.time()\n",
        "      test_loss, test_acc = test_step(epoch=epoch,\n",
        "                                      model=model,\n",
        "                                      dataloader=test_dataloader,\n",
        "                                      loss_fn=loss_fn,\n",
        "                                      device=device,\n",
        "                                      disable_progress_bar=disable_progress_bar)\n",
        "      test_epoch_end_time = time.time()\n",
        "      test_epoch_time = test_epoch_end_time - test_epoch_start_time\n",
        "\n",
        "      # Print out what's happening\n",
        "      print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f} | \"\n",
        "          f\"train_epoch_time: {train_epoch_time:.4f} | \"\n",
        "          f\"test_epoch_time: {test_epoch_time:.4f}\"\n",
        "      )\n",
        "\n",
        "      # Update results dictionary\n",
        "      results[\"train_loss\"].append(train_loss)\n",
        "      results[\"train_acc\"].append(train_acc)\n",
        "      results[\"test_loss\"].append(test_loss)\n",
        "      results[\"test_acc\"].append(test_acc)\n",
        "      results[\"train_epoch_time\"].append(train_epoch_time)\n",
        "      results[\"test_epoch_time\"].append(test_epoch_time)\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "kffIrbmHSnF7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GaP1kJ9iVwXU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}